{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting faster-whisper\n",
      "  Downloading faster_whisper-0.7.0-py3-none-any.whl (1.5 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting av==10.* (from faster-whisper)\n",
      "  Downloading av-10.0.0-cp311-cp311-macosx_11_0_arm64.whl (19.6 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m19.6/19.6 MB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting ctranslate2<4,>=3.17 (from faster-whisper)\n",
      "  Downloading ctranslate2-3.17.1-cp311-cp311-macosx_11_0_arm64.whl (1.1 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: huggingface-hub>=0.13 in /opt/homebrew/lib/python3.11/site-packages (from faster-whisper) (0.14.1)\n",
      "Requirement already satisfied: tokenizers==0.13.* in /opt/homebrew/lib/python3.11/site-packages (from faster-whisper) (0.13.3)\n",
      "Collecting onnxruntime<2,>=1.14 (from faster-whisper)\n",
      "  Downloading onnxruntime-1.15.1-cp311-cp311-macosx_11_0_arm64.whl (6.1 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.1/6.1 MB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: numpy in /opt/homebrew/lib/python3.11/site-packages (from ctranslate2<4,>=3.17->faster-whisper) (1.24.3)\n",
      "Requirement already satisfied: pyyaml<7,>=5.3 in /opt/homebrew/lib/python3.11/site-packages (from ctranslate2<4,>=3.17->faster-whisper) (6.0)\n",
      "Requirement already satisfied: filelock in /opt/homebrew/lib/python3.11/site-packages (from huggingface-hub>=0.13->faster-whisper) (3.12.0)\n",
      "Requirement already satisfied: fsspec in /opt/homebrew/lib/python3.11/site-packages (from huggingface-hub>=0.13->faster-whisper) (2023.5.0)\n",
      "Requirement already satisfied: requests in /opt/homebrew/lib/python3.11/site-packages (from huggingface-hub>=0.13->faster-whisper) (2.30.0)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /opt/homebrew/lib/python3.11/site-packages (from huggingface-hub>=0.13->faster-whisper) (4.65.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/homebrew/lib/python3.11/site-packages (from huggingface-hub>=0.13->faster-whisper) (4.5.0)\n",
      "Requirement already satisfied: packaging>=20.9 in /opt/homebrew/lib/python3.11/site-packages (from huggingface-hub>=0.13->faster-whisper) (23.1)\n",
      "Collecting coloredlogs (from onnxruntime<2,>=1.14->faster-whisper)\n",
      "  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting flatbuffers (from onnxruntime<2,>=1.14->faster-whisper)\n",
      "  Downloading flatbuffers-23.5.26-py2.py3-none-any.whl (26 kB)\n",
      "Requirement already satisfied: protobuf in /opt/homebrew/lib/python3.11/site-packages (from onnxruntime<2,>=1.14->faster-whisper) (4.23.1)\n",
      "Requirement already satisfied: sympy in /opt/homebrew/lib/python3.11/site-packages (from onnxruntime<2,>=1.14->faster-whisper) (1.12)\n",
      "Collecting humanfriendly>=9.1 (from coloredlogs->onnxruntime<2,>=1.14->faster-whisper)\n",
      "  Downloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m9.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: charset-normalizer<4,>=2 in /opt/homebrew/lib/python3.11/site-packages (from requests->huggingface-hub>=0.13->faster-whisper) (3.1.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/homebrew/lib/python3.11/site-packages (from requests->huggingface-hub>=0.13->faster-whisper) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/homebrew/lib/python3.11/site-packages (from requests->huggingface-hub>=0.13->faster-whisper) (1.26.15)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/homebrew/lib/python3.11/site-packages (from requests->huggingface-hub>=0.13->faster-whisper) (2023.5.7)\n",
      "Requirement already satisfied: mpmath>=0.19 in /opt/homebrew/lib/python3.11/site-packages (from sympy->onnxruntime<2,>=1.14->faster-whisper) (1.3.0)\n",
      "Installing collected packages: flatbuffers, av, humanfriendly, ctranslate2, coloredlogs, onnxruntime, faster-whisper\n",
      "Successfully installed av-10.0.0 coloredlogs-15.0.1 ctranslate2-3.17.1 faster-whisper-0.7.0 flatbuffers-23.5.26 humanfriendly-10.0 onnxruntime-1.15.1\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.1.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3.11 -m pip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install faster-whisper\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Unsupported model binary version. This executable supports models with binary version v6 or below, but the model has binary version v67324752. This usually means that the model was generated by a later version of CTranslate2. (Forward compatibility is not guaranteed.)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mfaster_whisper\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m model \u001b[39m=\u001b[39m faster_whisper\u001b[39m.\u001b[39;49mWhisperModel(\u001b[39m\"\u001b[39;49m\u001b[39m../whisper-base-ar-quran-faster/\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/faster_whisper/transcribe.py:124\u001b[0m, in \u001b[0;36mWhisperModel.__init__\u001b[0;34m(self, model_size_or_path, device, device_index, compute_type, cpu_threads, num_workers, download_root, local_files_only)\u001b[0m\n\u001b[1;32m    117\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    118\u001b[0m     model_path \u001b[39m=\u001b[39m download_model(\n\u001b[1;32m    119\u001b[0m         model_size_or_path,\n\u001b[1;32m    120\u001b[0m         local_files_only\u001b[39m=\u001b[39mlocal_files_only,\n\u001b[1;32m    121\u001b[0m         cache_dir\u001b[39m=\u001b[39mdownload_root,\n\u001b[1;32m    122\u001b[0m     )\n\u001b[0;32m--> 124\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel \u001b[39m=\u001b[39m ctranslate2\u001b[39m.\u001b[39;49mmodels\u001b[39m.\u001b[39;49mWhisper(\n\u001b[1;32m    125\u001b[0m     model_path,\n\u001b[1;32m    126\u001b[0m     device\u001b[39m=\u001b[39;49mdevice,\n\u001b[1;32m    127\u001b[0m     device_index\u001b[39m=\u001b[39;49mdevice_index,\n\u001b[1;32m    128\u001b[0m     compute_type\u001b[39m=\u001b[39;49mcompute_type,\n\u001b[1;32m    129\u001b[0m     intra_threads\u001b[39m=\u001b[39;49mcpu_threads,\n\u001b[1;32m    130\u001b[0m     inter_threads\u001b[39m=\u001b[39;49mnum_workers,\n\u001b[1;32m    131\u001b[0m )\n\u001b[1;32m    133\u001b[0m tokenizer_file \u001b[39m=\u001b[39m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mjoin(model_path, \u001b[39m\"\u001b[39m\u001b[39mtokenizer.json\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    134\u001b[0m \u001b[39mif\u001b[39;00m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39misfile(tokenizer_file):\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Unsupported model binary version. This executable supports models with binary version v6 or below, but the model has binary version v67324752. This usually means that the model was generated by a later version of CTranslate2. (Forward compatibility is not guaranteed.)"
     ]
    }
   ],
   "source": [
    "import faster_whisper\n",
    "model = faster_whisper.WhisperModel(\"../whisper-base-ar-quran-faster/\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
